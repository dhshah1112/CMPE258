{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aknKc-JISUTr",
        "outputId": "fd12afc0-327a-4646-b5ee-b84650ec3fab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/810.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/810.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m706.6/810.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n",
            "  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.31-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (3.7.1)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.33 langchain-text-splitters-0.0.1 langsmith-0.1.31 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9mvpU9QSjWL",
        "outputId": "e1f2ee6d-e5e3-4657-de4c-e7f0ea094f94"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.14.3-py3-none-any.whl (262 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/262.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/262.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zuC3nG1IT3br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.Zero Shot Prompting Agent\n",
        "\n",
        "A Zero Shot React Agent is capable of responding to prompts or questions without the need for specific prior training on those tasks. It leverages a pre-trained language model to generate responses based on its vast pre-existing knowledge. This type of agent is highly versatile and can be used in a wide range of applications, from answering factual questions to generating content based on given prompts. Its strength lies in its ability to provide immediate and relevant responses across diverse domains without needing customized training data for each new task.\n",
        "\n"
      ],
      "metadata": {
        "id": "LVMzx3VWUY1Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-r5fviwBupHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd85be70-45f6-4600-b41e-5e2b5b3eeec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "This is a highly debated topic and opinions may vary. Some of the most commonly mentioned names in discussions about the greatest batsman of all time include:\n",
            "\n",
            "1. Sir Don Bradman: The Australian batsman is often considered the greatest of all time due to his incredible batting average of 99.94 in test cricket.\n",
            "\n",
            "2. Sachin Tendulkar: The Indian batsman is the leading run-scorer in both test and one-day international cricket and is widely regarded as one of the greatest batsmen of all time.\n",
            "\n",
            "3. Sir Vivian Richards: The West Indian batsman was known for his aggressive and dominant style of play, earning him the nickname \"Master Blaster.\" He is considered one of the greatest batsmen in the history of the game.\n",
            "\n",
            "4. Brian Lara: The West Indian batsman holds the record for the highest individual score in test cricket and is often considered one of the most stylish and elegant batsmen to ever play the game.\n",
            "\n",
            "5. Ricky Ponting: The Australian batsman is the second-highest run-scorer in test cricket and is widely regarded as one of the greatest captains in the history of the game.\n",
            "\n",
            "6. Sir Jack Hobbs: The English batsman played in the early 20th century and is\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Initialize the LLM (Large Language Model)\n",
        "llm = OpenAI(api_key=\"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\")\n",
        "\n",
        "# Zero Shot React function\n",
        "def zero_shot_react(prompt):\n",
        "    response = llm(prompt)\n",
        "    return response\n",
        "\n",
        "# Example usage\n",
        "prompt = \"Who is the greatest batsman of all time?\"\n",
        "print(zero_shot_react(prompt))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.Conversational React Agent\n",
        "The Conversational React Agent is designed to engage in natural, back-and-forth conversations with users, maintaining context over the course of the interaction. This type of agent can remember previous exchanges within a conversation to provide coherent and contextually relevant responses. It's particularly suited for applications requiring a more human-like interaction experience, such as virtual assistants, customer service bots, and interactive storytelling applications. The Conversational React Agent helps create a more engaging and fluid conversation flow, enhancing user satisfaction."
      ],
      "metadata": {
        "id": "ZYYFPPDRUWNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Initialize the Large Language Model (LLM)\n",
        "llm = OpenAI(api_key=\"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\")\n",
        "\n",
        "# Function to simulate a conversational agent\n",
        "def simple_conversational_agent(prompt, history=[]):\n",
        "    # Combine the conversation history with the new prompt\n",
        "    full_prompt = \"\\n\".join(history + [prompt])\n",
        "    # Generate a response using the LLM\n",
        "    response = llm(full_prompt)\n",
        "    # Update the conversation history\n",
        "    history.append(prompt)\n",
        "    history.append(response)\n",
        "    return response\n",
        "\n",
        "# Example usage\n",
        "history = []\n",
        "user_prompt = \"Hello, how are you?\"\n",
        "print(simple_conversational_agent(user_prompt, history))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTNltt0EVSj8",
        "outputId": "ea5f875d-a774-4a45-f447-ce5a60bae8ee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "I am an AI and do not have feelings like humans do, but thank you for asking. How can I assist you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Continuing the conversation with the simple conversational agent\n",
        "\n",
        "user_prompt_2 = \"What can you tell me about the Eiffel Tower?\"\n",
        "print(simple_conversational_agent(user_prompt_2, history))\n",
        "\n",
        "\n",
        "user_prompt_3 = \"How tall is it?\"\n",
        "print(simple_conversational_agent(user_prompt_3, history))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnzJ7gKlU049",
        "outputId": "e6619e0e-b2c4-4469-dc53-85cee1787b6d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The Eiffel Tower is a famous landmark located in Paris, France. It was built in 1889 and stands at 324 meters tall. It was originally constructed as the entrance to the 1889 World's Fair and was supposed to be temporary, but it became a popular attraction and was never taken down. It is made of iron and has three levels open to visitors, with restaurants and observation decks offering stunning views of the city. It is considered to be one of the most iconic structures in the world and is visited by millions of people each year.\n",
            "\n",
            "\n",
            "The Eiffel Tower stands at 324 meters tall (or 1063 feet).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.React Docstore Agent\n",
        "A React Docstore Agent utilizes a document store to inform its responses with data-driven insights. This agent type searches through a repository of documents to find relevant information that can support or provide answers to user queries. It's especially useful for applications where responses need to be backed by specific data or documented information, such as knowledge bases, FAQ bots, or research assistants. By integrating with a document store, this agent can provide accurate, informed reactions based on the content of the documents it has access to.\n",
        "\n"
      ],
      "metadata": {
        "id": "zROIZmirUsFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDocStore:\n",
        "    def __init__(self):\n",
        "        self.documents = [\n",
        "            {\"keywords\": [\"eiffel\", \"tower\", \"paris\"], \"response\": \"The Eiffel Tower is in Paris.\"},\n",
        "            {\"keywords\": [\"python\", \"programming\", \"language\"], \"response\": \"Python is a popular programming language.\"}\n",
        "        ]\n",
        "\n",
        "    def get_relevant_response(self, query):\n",
        "        query_keywords = set(query.lower().split())\n",
        "        for doc in self.documents:\n",
        "            if any(keyword in query_keywords for keyword in doc[\"keywords\"]):\n",
        "                return doc[\"response\"]\n",
        "        return \"I couldn't find anything relevant in my documents.\"\n",
        "\n",
        "# Example usage with improved logic\n",
        "doc_store = SimpleDocStore()\n",
        "\n",
        "def answer_question_with_docs(question):\n",
        "    return doc_store.get_relevant_response(question)\n",
        "\n",
        "# Testing the function with different questions\n",
        "question1 = \"Where is the Eiffel Tower?\"\n",
        "print(answer_question_with_docs(question1))\n",
        "\n",
        "question2 = \"What is Python known for?\"\n",
        "print(answer_question_with_docs(question2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfyadhDIV8tl",
        "outputId": "6660f859-47fc-43cb-bbe7-8a9bb9cfc1d6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Eiffel Tower is in Paris.\n",
            "Python is a popular programming language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AWcENjvhUuA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4.Self Ask with Search Agent\n",
        "The Self Ask with Search Agent is adept at performing searches or querying databases to gather information that guides its responses or actions. This agent can autonomously search external databases or the internet to find answers or gather information related to the user's query. It's particularly valuable in scenarios where the agent needs to provide up-to-date information or when answers are not contained within a pre-defined knowledge base. Applications include information retrieval systems, data analysis tools, and interactive learning environments where the agent can supplement its knowledge by searching for and incorporating external information sources."
      ],
      "metadata": {
        "id": "mlbDKBkTUzKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"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\""
      ],
      "metadata": {
        "id": "pjEWhTxIYBCK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW1hF9xNYPlp",
        "outputId": "37301cad-4631-4daa-a0e5-2a8285464135"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, SerpAPIWrapper\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "\n",
        "search = SerpAPIWrapper(serpapi_api_key='api_key')\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Intermediate Answer\",\n",
        "        func=search.run,\n",
        "        description='google search'\n",
        "    )\n",
        "]\n",
        "\n",
        "self_ask_with_search = initialize_agent(tools, llm, agent=\"self-ask-with-search\", verbose=True)"
      ],
      "metadata": {
        "id": "48viaoVcXab9"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#This is the first-choice agent to use when using LLM's to extract information with a search engine. The agent will ask follow-up questions and use the search functionality to get intermediate answers that help it get to a final answer.\n",
        "Serpapi key will be required for this to run"
      ],
      "metadata": {
        "id": "XfUGoLDNaZ0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(self_ask_with_search.agent.llm_chain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWeW2Lp5X_T6",
        "outputId": "229dc5dc-bc50-42a7-f13d-8903eb2d770c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: How old was Muhammad Ali when he died?\n",
            "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
            "Follow up: How old was Alan Turing when he died?\n",
            "Intermediate answer: Alan Turing was 41 years old when he died.\n",
            "So the final answer is: Muhammad Ali\n",
            "\n",
            "Question: When was the founder of craigslist born?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the founder of craigslist?\n",
            "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
            "Follow up: When was Craig Newmark born?\n",
            "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
            "So the final answer is: December 6, 1952\n",
            "\n",
            "Question: Who was the maternal grandfather of George Washington?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the mother of George Washington?\n",
            "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
            "Follow up: Who was the father of Mary Ball Washington?\n",
            "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
            "So the final answer is: Joseph Ball\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who is the director of Jaws?\n",
            "Intermediate answer: The director of Jaws is Steven Spielberg.\n",
            "Follow up: Where is Steven Spielberg from?\n",
            "Intermediate answer: The United States.\n",
            "Follow up: Who is the director of Casino Royale?\n",
            "Intermediate answer: The director of Casino Royale is Martin Campbell.\n",
            "Follow up: Where is Martin Campbell from?\n",
            "Intermediate answer: New Zealand.\n",
            "So the final answer is: No\n",
            "\n",
            "Question: {input}\n",
            "Are followup questions needed here:{agent_scratchpad}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nyk87u90iPLY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}